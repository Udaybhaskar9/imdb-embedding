{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_P6dIzye9Gqn"
      },
      "outputs": [],
      "source": [
        "# imdb_embeddings.py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Load IMDB\n",
        "vocab_size = 20000\n",
        "maxlen = 200\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test  = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Build model with Embedding\n",
        "embedding_dim = 128\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(maxlen,)),\n",
        "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen, name='imdb_embedding'),\n",
        "    layers.Bidirectional(layers.LSTM(64, return_sequences=False)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train\n",
        "model.fit(x_train, y_train, validation_split=0.1, epochs=6, batch_size=128)\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(f\"IMDB test accuracy: {acc:.4f}\")\n",
        "\n",
        "# Extract embedding weights\n",
        "embedding_layer = model.get_layer('imdb_embedding')\n",
        "embeddings = embedding_layer.get_weights()[0]  # shape: (vocab_size, embedding_dim)\n",
        "print(\"embeddings shape:\", embeddings.shape)\n",
        "\n",
        "# Save embeddings to file (numpy)\n",
        "np.save(\"imdb_embeddings.npy\", embeddings)\n",
        "model.save(\"imdb_embedding_model.h5\")"
      ]
    }
  ]
}